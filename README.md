# DocuDive
GPT for your wiki pages

- Based off of PrivateGPT - https://github.com/imartinez/privateGPT

## Contributors
- [c0demode](https://github.com/c0demode)
- [Larry Battle](https://github.com/LarryBattle)
- [Bryce Duncan](https://github.com/BryceDuncan)
- [na]()
- brayanpena530
- [Alexander Schulz](https://github.com/alxschlz98)

## Schedule
### v1.0 - Local: CLI 
* Due by June 15, 2023 1pm
- (B/P/Br) Pick a LLM / VectorStore project to use. (PrivateGPT, H2OGPT, LlamaIndex)
- (B/P/Br) Load models into LLM locally to have the demo work
- (B/P/Br) Upload the formatted data into the LLM locally
- (B/P) Launch the LLM locally
- (W) Create confluence page or wiki server
- (W) Create fake product pages
- (W) Import fake product pages into wiki / confluence
- (W) Export the confluence pages
- (W/L) Format the confluence exported data to work with the LLM
- (Br) Create architecture diagram
- (L) Update readme.md
- (L) Create queries to testing the LLM / VectorStore

### v1.1 - Local: Microservice
* Due by June 15, 2023 3pm
- (L) Create the architecture and API contracts for each main modules
- (B) Choose the microservice frameworks
- (B) Create a microservice to use for the LLM / VectorStore
- (Br) Create a setup document of have to integrate this with a existing confluence site
- (L/W) Create a report to show the data accuracy / confusion matrix of the LLM / VectorStore vs Confluence search
- (L) Have a e2e tests that hit the LLM microservice endpoints

### v1.2 - Local: UI
* Due by June 15, 2023 5pm
- (A) Choose the UI framework
- (A) Create UI microservice for querying the LLM / VectorStore
- (A) Launch UI locally

### v1.3 - AWS: Microservice
* Due by June 15, 2023 5pm
- (P) Upload the formatted data into the LLM in AWS
- (P) Launch the LLM in AWS
- (P) Load models into LLM in AWS to have the demo work


### v1.4 - AWS: UI
* Due June 16 9:30am
- (A) Launch UI in AWS

### Create presentation
* by June 15, 10pm
- (L) Create presentation
- (L) Create video of the hackathon 
- (L) Upload to Youtube
